# README - scripts/

โฟลเดอร์นี้รวมทุกสคริปต์ที่เกี่ยวกับ AI/ML สำหรับ Virtual Trainer AI

## สรุปหน้าที่แต่ละไฟล์ (อธิบายละเอียดสำหรับมือใหม่)

---

### 1. extract_landmarks.py
**หน้าที่:**
- ดึง "จุดข้อต่อ" (landmark) จากวิดีโอตัวอย่างแต่ละท่า (เช่น Squat, Push-up, Plank)
- ใช้ MediaPipe ตรวจจับจุดสำคัญบนร่างกายในแต่ละเฟรมของวิดีโอ
- เก็บข้อมูลจุดเหล่านี้ (feature) และชื่อท่า (label) ลงไฟล์ X.npy, y.npy

**เหมาะกับ:**
- เตรียมข้อมูลสำหรับเทรน AI
- ต้องรันก่อน train_model.py

**วิธีใช้:**
1. วางวิดีโอตัวอย่างแต่ละท่าในโฟลเดอร์ `../videos/` (เช่น `../videos/Squat/`)
2. รันคำสั่ง:
   ```sh
   python extract_landmarks.py
   ```
3. จะได้ไฟล์ `../data/X.npy` และ `../data/y.npy` สำหรับใช้เทรนโมเดล

---

### 2. train_model.py
**หน้าที่:**
- เทรนโมเดล AI (RandomForest) ให้รู้จักแยกแยะท่าออกกำลังกายจากข้อมูล landmark
- ใช้ข้อมูล X.npy, y.npy ที่ได้จาก extract_landmarks.py
- ประเมินความแม่นยำของโมเดล และบันทึกโมเดลที่เทรนแล้วเป็นไฟล์ exercise_classifier.joblib

**เหมาะกับ:**
- สร้างโมเดล AI สำหรับใช้งานจริง
- ต้องรันหลังจากเตรียมข้อมูล landmark แล้ว

**วิธีใช้:**
```sh
python train_model.py
```
- จะได้ไฟล์ `../data/exercise_classifier.joblib` สำหรับนำไปใช้ทำนายจริง

---

### 3. ml_core.py
**หน้าที่:**
- รวมฟังก์ชันหลักเกี่ยวกับ AI/ML ทั้งหมด (core logic)
- เช่น: การทำนายท่าออกกำลังกายจากวิดีโอ, การคำนวณมุมข้อต่อ, การประเมินฟอร์ม, การให้ feedback
- ใช้ซ้ำได้ทั้งใน CLI และ backend (แต่ backend ไม่ควร import ตรง)

**เหมาะกับ:**
- เป็นคลังฟังก์ชันกลางสำหรับงาน AI/ML ในโปรเจกต์นี้
- ไม่ควรรันไฟล์นี้โดยตรง

**ตัวอย่างฟังก์ชัน:**
- `predict_exercise_from_video(video_path)` : ทำนายท่าออกกำลังกายจากวิดีโอ
- `calculate_angle(a, b, c)` : คำนวณมุมระหว่าง 3 จุด
- `check_squat_form(landmarks)` : ประเมินฟอร์ม squat
- `score_squat_form(landmarks)` : ให้คะแนนฟอร์ม squat

---

### 4. predict_video.py
**หน้าที่:**
- สคริปต์สำหรับ "ทำนายท่าออกกำลังกาย" จากวิดีโอใหม่ (ที่ user อัปโหลด)
- ใช้โมเดลที่เทรนแล้ว (exercise_classifier.joblib) และฟังก์ชันจาก ml_core.py
- แสดงผลลัพธ์ (เช่น ท่าที่ทายได้, feedback, คะแนนฟอร์ม) บนวิดีโอ output
- สามารถเลือกไฟล์ input/output แบบ interactive ได้
- บันทึกผลลัพธ์ลงไฟล์ user_results.json (optionally)

**เหมาะกับ:**
- ทดสอบ AI กับวิดีโอใหม่
- สร้างวิดีโอ output ที่มี overlay feedback

**วิธีใช้:**
```sh
python predict_video.py
```
- เลือกไฟล์วิดีโอ input ตามเมนู
- จะได้ไฟล์ output ในโฟลเดอร์ `../results/`

---

### 5. analyze_and_recommend.py
**หน้าที่:**
- ตัวอย่าง logic สำหรับ "แนะนำโปรแกรมฝึกถัดไป" ตามเป้าหมายของ user และประวัติการฝึก
- อ่านผลลัพธ์จาก user_results.json (ถ้ามี)
- เลือกโปรแกรมถัดไปและสุ่มวิดีโอตัวอย่างให้ user

**เหมาะกับ:**
- สาธิตการแนะนำโปรแกรมฝึก (demo)
- ยังไม่เชื่อมกับ backend จริง

**วิธีใช้:**
```sh
python analyze_and_recommend.py
```
- กรอก user_id และเป้าหมายตามเมนู
- จะแสดงโปรแกรมถัดไปและวิดีโอตัวอย่าง

---

## หมายเหตุสำหรับมือใหม่
- ทุกไฟล์ในนี้ (ยกเว้น ml_core.py) สามารถรันได้จาก command line
- ถ้าไม่แน่ใจว่าต้องรันไฟล์ไหนก่อน ให้เริ่มจาก extract_landmarks.py → train_model.py → predict_video.py
- ถ้าติดปัญหาเรื่อง path หรือไฟล์ไม่เจอ ให้ตรวจสอบว่าโฟลเดอร์ data/, videos/, results/ มีอยู่จริง
- ถาม AI หรือผู้ดูแลโปรเจกต์ได้เสมอ!
